Potential Areas of Further Research
- Use nnUNet as a baseline instead of UNet (A semantic segmentation method that automatically adapts to a given dataset. It will analyze the provided training cases and automatically configure a matching U-Net-based segmentation pipeline)
- Investigation into better Model Architecture/Design (Using a Basic 5 Layer U-Net for now, can look to expand/improve on this once the research topic is narrowed)

Novel Ideas
- Anatomically-Guided 3D Jigsaw Pretext Task
  - Create a bounding box around the kidney region, perform Jigsaw SSL within the bounding box only; this way, we only want to encourage learning of the kidney-tumour relationship.
  - Add On: Once dividing into patches, add some form of noise to force the model to de-noise it
https://arxiv.org/pdf/2308.05770
https://arxiv.org/html/2404.07292v1 (This one masks specific patches to force the model to fully regenerate it)

- Cross-Scale Feature Alignment (Multi-Resolution SSL)
  - Divide the image into Patches, perform feature extraction of the same patch at different scales or resolutions and align them in feature space. Enables ability to find multi-scale features (Global Kidney vs Local Tumor)
https://arxiv.org/pdf/2401.15855 (Multi-Scale)
https://www.researchgate.net/publication/377321015_Multi-Scale_Image-_and_Feature-Level_Alignment_for_Cross-Resolution_Person_Re-Identification
https://www.sciencedirect.com/science/article/pii/S0031320324003728

- Ask Dr. Akilan for feedback on research topics, additionally ask him if he has any ideas

## Anatomically-Guided 3D Jigsaw Pretext Task
- ROI-Guided Inpainting (Mittal et al., 2021) – This work uses a brain tumor segmentation task to illustrate ROI-guided SSL. They pre-train a U-Net on an inpainting task where mask regions are restricted to areas overlapping the tumor segmentation mask. In effect, the network learns to reconstruct tumor regions, which “teaches” it tumor-specific features. On Brats (brain tumor) and WMH (brain lesions) datasets, their ROI-focused inpainting yields higher segmentation accuracy than random-mask SSL or even fully supervised baselines
- Region-Guided Masked Modeling (Li et al., 2022) – This method (RGMIM) applies ROI guidance to masked-image modeling in chest X-rays. Using a lung mask, they identify which image patches fall within the lung region and preferentially mask those patches for the pretext task. By focusing only on lung areas, the ViT learns more relevant features for lung disease. Experiments show RGMIM substantially outperforms unguided masking (and other SSL methods) on lung pathology detection. This approach is analogous to a bounding-box strategy: the organ mask defines a “bounding box” (here the lung) for self-supervision.
- Organ-Centric Pretext (Shah et al., 2021) – For kidney CT segmentation, Shah et al. design a proxy task that uses kidney ROIs. Each kidney is cropped from the CT (using the kidney mask) into a fixed size volume (~64×112×112). A Siamese network then learns to predict whether a pair of kidney crops come from the same (left/right) side. In effect, the model must learn the shape and appearance of kidneys. Importantly, only the kidney region is fed to the network, ignoring the rest of the abdomen. This self-supervised pretraining on KiTS data led to faster convergence and better segmentation than training from scratch. This is directly analogous to using a bounding box around the kidney (and tumor) for SSL – here they implicitly learn kidney-specific features by focusing on the kidney crops.
- 3D Jigsaw and Related 3D SSL (Azizi et al., 2020) – Azizi et al. propose a suite of 3D SSL tasks for volumetric medical images, including a 3D Jigsaw puzzle task. In their method, a 3D volume is split into subcubes and the network learns to predict the correct ordering. They show that 3D pretraining (including 3D Jigsaw) yields richer anatomical features than 2D pretraining. While Azizi et al.’s 3D Jigsaw is not restricted to an ROI, it demonstrates that puzzle-based SSL can work in 3D medical contexts. One could imagine applying this idea within a kidney bounding box (as they note: using a mask to guide which blocks to shuffle would force learning finer organ-level structures).

## Cross-Scale Feature Alignment (Multi-Resolution SSL)
- Mask-in-Mask (MiM) – Zhuang et al. (2024) propose MiM, a hierarchical SSL framework for 3D volumetric data. MiM generates multi-level masked sub-volumes (coarse and fine views of the same patch) and simultaneously reconstructs them. Crucially, it enforces cross-level alignment: feature representations of adjacent levels are contrasted so that corresponding anatomical structures (e.g. kidney tissue) are brought together in feature space. MiM’s cross-level alignment loss thereby ensures that high-resolution and low-resolution features of the same volume are consistent. Pre trained on large CT corpora, MiM significantly boosts downstream organ/tumor segmentation (e.g. kidney, liver) compared to single-scale MAE baselines
- MsVRL (Multiscale Visual Representation Learning) – Zheng et al. (IEEE TMI 2023) introduce MsVRL, a multi-scale SSL pretraining for 3D medical segmentation. They note that organs and lesions have varying physical sizes, so MsVRL enforces cross-level consistency between features at different resolutions. In practice, MsVRL randomly crops larger “canvas” regions and extracts multi-scale patches. A novel cross-level consistent loss (contrastive) is used so that features of the same location at different scales match in representation. Additional modules (a pre-sampling branch and centerness branch) help focus on organ centers. Pretraining on unlabeled scans and finetuning on tasks like abdominal organ and kidney–tumor segmentation, MsVRL outperforms standard SSL baselines, indicating its multi-scale alignment improves the learned embeddings
- Multi-Resolution Transformers (MR-Trans) – Zou et al. (Comput. Biol. Med. 2023) design MR-Trans, a segmentation network with separate branches processing different resolutions of the input. A branch-partition module splits the input into, for example, high-res and low-res streams. Each branch has its own Swin-transformer encoder, and a feature fusion strategy merges corresponding features between branches. The decoder combines pyramid pooling (PSPNet) and feature pyramid (FPN) ideas to integrate multi-scale context. In effect, MR-Trans simultaneously maintains high- and low-resolution feature maps and aligns them via fusion, which improves recognition of both small lesions (fine scale) and overall organ structure (coarse scale)
- Hierarchical ViT with Multi-Scale SSL (HMSViT) – Zhang et al. (arXiv 2025) propose HMSViT for corneal nerve segmentation, but its hierarchical design is broadly applicable. It uses a pooling-based hierarchical transformer that captures fine details in early layers and global context in deeper layers. A block-masked self-supervised pretraining further enforces consistency of features across scales. In experiments, HMSViT’s multi-scale encoder combined with SSL yields state-of-the-art segmentation accuracy. While specific to 2D images, HMSViT illustrates how a hierarchical architecture (fine-to coarse) can be coupled with self-supervised alignment losses to learn robust multi-scale representations
